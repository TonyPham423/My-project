{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detector Using Tensorflow and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of With mask vs Without Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Mask:  1916\n",
      "Without Mask:  1919\n"
     ]
    }
   ],
   "source": [
    "print(\"With Mask: \",len(os.listdir('dataset/with_mask')))\n",
    "print(\"Without Mask: \",len(os.listdir('dataset/without_mask')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAIN, TEST, SPLIT_SIZE):\n",
    "    proper_data = []\n",
    "    for img in os.listdir(SOURCE):\n",
    "        img_path = SOURCE + img\n",
    "        if(os.path.getsize(img_path)>0):\n",
    "            proper_data.append(img)\n",
    "        else:\n",
    "            print(\"Issue in the Image:\"+ img_path)\n",
    "            \n",
    "    training_size = int(len(proper_data)*SPLIT_SIZE)\n",
    "    shuffled_data = random.sample(proper_data, len(proper_data))\n",
    "    training_data = shuffled_data[:training_size]\n",
    "    testing_data = shuffled_data[training_size:]\n",
    "    #print(training_data)\n",
    "    for img in training_data:\n",
    "        temp_img = SOURCE + img\n",
    "        train_img = TRAIN + img\n",
    "        copyfile(temp_img, train_img)\n",
    "\n",
    "    for img in testing_data:\n",
    "        temp_img = SOURCE + img\n",
    "        test_img = TEST + img\n",
    "        copyfile(temp_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "YES_Source = 'dataset/with_mask/'\n",
    "TRAINING_YES_Source = 'dataset/train/with_mask/'\n",
    "TESTING_YES_Source = 'dataset/test/with_mask/'\n",
    "NO_Source = 'dataset/without_mask/'\n",
    "TRAINING_NO_Source = 'dataset/train/without_mask/'\n",
    "TESTING_NO_Source = 'dataset/test/without_mask/'\n",
    "split_size = 0.8\n",
    "split_data(YES_Source, TRAINING_YES_Source, TESTING_YES_Source, split_size)\n",
    "split_data(NO_Source, TRAINING_NO_Source, TESTING_NO_Source, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training with mask:  1916\n",
      "Number of training without mask:  1914\n",
      "Number of testing with mask:  1040\n",
      "Number of testing without mask:  1025\n"
     ]
    }
   ],
   "source": [
    "print('Number of training with mask: ', len(os.listdir(TRAINING_YES_Source)))\n",
    "print('Number of training without mask: ', len(os.listdir(TRAINING_NO_Source)))\n",
    "print('Number of testing with mask: ', len(os.listdir(TESTING_YES_Source)))\n",
    "print('Number of testing without mask: ', len(os.listdir(TESTING_NO_Source)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating CNN Model using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3828 images belonging to 2 classes.\n",
      "Found 2065 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = 'dataset/train/'\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                    target_size = (150,150),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size = 32)\n",
    "TEST_DIR = 'dataset/test/'\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                target_size = (150,150),\n",
    "                                                class_mode='categorical',\n",
    "                                                batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to get best weights used when monitored with validation loss\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\AppData\\Local\\Temp\\ipykernel_29412\\288473390.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 34/120 [=======>......................] - ETA: 16s - loss: 0.6417 - accuracy: 0.6737"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.8051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 33s 244ms/step - loss: 0.4384 - accuracy: 0.8051 - val_loss: 0.2173 - val_accuracy: 0.9293\n",
      "Epoch 2/30\n",
      " 15/120 [==>...........................] - ETA: 20s - loss: 0.3082 - accuracy: 0.8896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 230ms/step - loss: 0.3141 - accuracy: 0.8770 - val_loss: 0.2395 - val_accuracy: 0.9104\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.8911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 29s 240ms/step - loss: 0.2879 - accuracy: 0.8911 - val_loss: 0.1788 - val_accuracy: 0.9356\n",
      "Epoch 4/30\n",
      " 25/120 [=====>........................] - ETA: 17s - loss: 0.2525 - accuracy: 0.8975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.8924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 228ms/step - loss: 0.2748 - accuracy: 0.8924 - val_loss: 0.1539 - val_accuracy: 0.9462\n",
      "Epoch 5/30\n",
      " 16/120 [===>..........................] - ETA: 19s - loss: 0.2648 - accuracy: 0.8828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 26s 219ms/step - loss: 0.2734 - accuracy: 0.8903 - val_loss: 0.1541 - val_accuracy: 0.9477\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.9015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-006.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-006.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 236ms/step - loss: 0.2510 - accuracy: 0.9015 - val_loss: 0.1524 - val_accuracy: 0.9462\n",
      "Epoch 7/30\n",
      " 90/120 [=====================>........] - ETA: 5s - loss: 0.2428 - accuracy: 0.8992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.2452 - accuracy: 0.9007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-007.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-007.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 236ms/step - loss: 0.2452 - accuracy: 0.9007 - val_loss: 0.1413 - val_accuracy: 0.9501\n",
      "Epoch 8/30\n",
      "  7/120 [>.............................] - ETA: 22s - loss: 0.2312 - accuracy: 0.9196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 30s 249ms/step - loss: 0.2308 - accuracy: 0.9109 - val_loss: 0.1715 - val_accuracy: 0.9341\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.9188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-009.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-009.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 233ms/step - loss: 0.2140 - accuracy: 0.9188 - val_loss: 0.1332 - val_accuracy: 0.9569\n",
      "Epoch 10/30\n",
      " 27/120 [=====>........................] - ETA: 17s - loss: 0.2211 - accuracy: 0.9155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-010.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-010.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 231ms/step - loss: 0.2167 - accuracy: 0.9164 - val_loss: 0.1143 - val_accuracy: 0.9554\n",
      "Epoch 11/30\n",
      " 61/120 [==============>...............] - ETA: 10s - loss: 0.2019 - accuracy: 0.9186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 26s 216ms/step - loss: 0.2110 - accuracy: 0.9130 - val_loss: 0.1179 - val_accuracy: 0.9642\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-012.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-012.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 232ms/step - loss: 0.2048 - accuracy: 0.9229 - val_loss: 0.1113 - val_accuracy: 0.9617\n",
      "Epoch 13/30\n",
      " 94/120 [======================>.......] - ETA: 4s - loss: 0.1923 - accuracy: 0.9269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 27s 226ms/step - loss: 0.1979 - accuracy: 0.9258 - val_loss: 0.1167 - val_accuracy: 0.9564\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-014.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-014.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 27s 227ms/step - loss: 0.1953 - accuracy: 0.9240 - val_loss: 0.1017 - val_accuracy: 0.9646\n",
      "Epoch 15/30\n",
      " 14/120 [==>...........................] - ETA: 18s - loss: 0.1410 - accuracy: 0.9487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-015.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-015.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 232ms/step - loss: 0.1798 - accuracy: 0.9336 - val_loss: 0.0966 - val_accuracy: 0.9651\n",
      "Epoch 16/30\n",
      " 41/120 [=========>....................] - ETA: 15s - loss: 0.1752 - accuracy: 0.9385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 27s 228ms/step - loss: 0.1815 - accuracy: 0.9323 - val_loss: 0.0999 - val_accuracy: 0.9676\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 27s 227ms/step - loss: 0.1750 - accuracy: 0.9321 - val_loss: 0.0979 - val_accuracy: 0.9680\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-018.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-018.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 232ms/step - loss: 0.1778 - accuracy: 0.9355 - val_loss: 0.0865 - val_accuracy: 0.9738\n",
      "Epoch 19/30\n",
      " 18/120 [===>..........................] - ETA: 19s - loss: 0.1449 - accuracy: 0.9601"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 29s 242ms/step - loss: 0.1700 - accuracy: 0.9389 - val_loss: 0.1176 - val_accuracy: 0.9574\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-020.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-020.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 233ms/step - loss: 0.1655 - accuracy: 0.9360 - val_loss: 0.0839 - val_accuracy: 0.9743\n",
      "Epoch 21/30\n",
      " 41/120 [=========>....................] - ETA: 14s - loss: 0.1949 - accuracy: 0.9300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-021.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-021.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 231ms/step - loss: 0.1714 - accuracy: 0.9386 - val_loss: 0.0817 - val_accuracy: 0.9700\n",
      "Epoch 22/30\n",
      " 16/120 [===>..........................] - ETA: 18s - loss: 0.1649 - accuracy: 0.9355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-022.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-022.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 232ms/step - loss: 0.1659 - accuracy: 0.9383 - val_loss: 0.0775 - val_accuracy: 0.9700\n",
      "Epoch 23/30\n",
      " 42/120 [=========>....................] - ETA: 15s - loss: 0.1727 - accuracy: 0.9330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 230ms/step - loss: 0.1610 - accuracy: 0.9436 - val_loss: 0.0849 - val_accuracy: 0.9709\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 28s 233ms/step - loss: 0.1617 - accuracy: 0.9423 - val_loss: 0.1231 - val_accuracy: 0.9540\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 29s 239ms/step - loss: 0.1522 - accuracy: 0.9423 - val_loss: 0.0884 - val_accuracy: 0.9695\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 29s 239ms/step - loss: 0.1493 - accuracy: 0.9454 - val_loss: 0.0842 - val_accuracy: 0.9709\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-027.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-027.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 28s 234ms/step - loss: 0.1526 - accuracy: 0.9454 - val_loss: 0.0739 - val_accuracy: 0.9748\n",
      "Epoch 28/30\n",
      " 34/120 [=======>......................] - ETA: 15s - loss: 0.1650 - accuracy: 0.9393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phatk\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 30s 246ms/step - loss: 0.1543 - accuracy: 0.9436 - val_loss: 0.0914 - val_accuracy: 0.9695\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 0.1417 - accuracy: 0.9428 - val_loss: 0.0787 - val_accuracy: 0.9743\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 31s 261ms/step - loss: 0.1539 - accuracy: 0.9423 - val_loss: 0.1033 - val_accuracy: 0.9632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             epochs = 30,\n",
    "                             validation_data=test_generator,\n",
    "                             callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Remove the commented Code lines to save your Video'''\n",
    "\n",
    "labels = {0:'No Mask, Please wear it!',1:'Mask On, Good work!'}\n",
    "color = {0:(0,0,255), 1:(0,255,0)}\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "classifier = cv2.CascadeClassifier('dataset/haarcascade_frontalface_default.xml')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'ADV1') ######\n",
    "out = cv2.VideoWriter('lol.mp4', fourcc, 25, (640,480)) ######\n",
    "while webcam.isOpened():\n",
    "    _, frame = webcam.read()\n",
    "    frame = cv2.flip(frame, 1, 1)\n",
    "    faces = classifier.detectMultiScale(frame, 1.1, 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "#         cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2) ######\n",
    "        face_data = frame[y:y+h, x:x+w]\n",
    "        resize_data = cv2.resize(face_data, (150,150))\n",
    "        resize_data = resize_data/255.0\n",
    "        final_data = np.expand_dims(resize_data, axis = 0)\n",
    "        prediction = model.predict(final_data)\n",
    "        \n",
    "        binary_answer = np.argmax(prediction,axis=1)[0]\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), color[binary_answer], 2)\n",
    "#         cv2.rectangle(frame, (x,y-40), (x+w, y), color[binary_answer], -1) no solid\n",
    "        cv2.putText(frame, labels[binary_answer], (x,y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)   \n",
    "\n",
    "    cv2.imshow(\"Face mask detection\", frame)\n",
    "    out.write(frame) ######\n",
    "    if cv2.waitKey(1) == 27:\n",
    "            break  \n",
    "\n",
    "out.release() ######\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
